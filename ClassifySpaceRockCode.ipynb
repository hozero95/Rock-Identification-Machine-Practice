{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 식별 머신을 위한 데이터를 준비한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리를 불러 온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 플로팅 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 숫자 처리 라이브러리\n",
    "import numpy as np\n",
    "\n",
    "# 딥러닝을 위한 파이토치 라이브러리\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# 토치비전 라이브러리\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# 이미지 처리 라이브러리 (PIL, pillow)\n",
    "from PIL import Image\n",
    "\n",
    "# 주피터 노트북에서 plot이 보이도록 설정\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 디렉토리, 분할 비율, 변환 방법을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터가 있는 디렉토리와 데이터 세트 분할 비율(valid_size)을 정한다.\n",
    "data_dir = './data'\n",
    "valid_size = 0.2 # 학습 데이터와 검증(테스트) 데이터의 분할 비율(8:2)\n",
    "\n",
    "# 이미지 데이터를 ResNet50에서 다룰 수 있도록 변환시키는 방법을 정한다. (t_transforms)\n",
    "t_transforms = transforms.Compose([\n",
    "               transforms.RandomResizedCrop(224),\n",
    "               transforms.Resize(224),\n",
    "               transforms.ToTensor()\n",
    "])\n",
    "# convert image size to 224x224 for ResNet50 after crop\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 변환 방법을 출력하여 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 설정한 이미지 데이터 변환 방법을 출력하여 확인한다.\n",
    "print(t_transforms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 로딩 함수를 작성한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (연습) trainloader와 testloader를 만들어 본다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 학습 데이터 세트 및 테스트 데이터 세트의 디렉토리 및 변환 방식을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 155\n",
      "    Root location: ./data\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "               Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n",
      "155 155\n"
     ]
    }
   ],
   "source": [
    "# datasets.ImageFolder를 사용해서 학습 데이터(train_data)와 테스트 데이터(test_data)를 만든다.\n",
    "# make train_data and test_data using datasets.ImageFolder\n",
    "train_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "\n",
    "# 학습 데이터의 형식을 확인한다.\n",
    "print(train_data)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터의 길이를 확인한다.\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터세트를 섞기 위해, 우선 인덱스를 만들어 랜덤하게 섞는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154]\n",
      "[131, 86, 3, 33, 105, 138, 14, 55, 66, 75, 127, 51, 72, 103, 88, 92, 22, 29, 19, 94, 91, 102, 108, 27, 93, 1, 76, 149, 101, 49, 100, 67, 113, 123, 147, 146, 65, 43, 17, 60, 20, 121, 24, 35, 62, 118, 28, 70, 140, 16, 84, 114, 45, 12, 119, 82, 37, 30, 6, 10, 96, 144, 50, 79, 71, 129, 58, 141, 25, 31, 98, 132, 59, 104, 130, 44, 32, 23, 11, 136, 56, 124, 83, 26, 106, 143, 9, 18, 109, 85, 41, 48, 38, 135, 64, 57, 81, 142, 68, 95, 112, 0, 47, 2, 40, 139, 115, 13, 153, 110, 116, 89, 145, 52, 90, 128, 42, 8, 15, 77, 46, 34, 99, 87, 154, 122, 4, 54, 53, 7, 21, 137, 117, 36, 69, 134, 111, 148, 80, 97, 151, 125, 74, 120, 107, 152, 39, 61, 133, 78, 73, 126, 63, 150, 5]\n"
     ]
    }
   ],
   "source": [
    "# train_data 사이즈만큼의 정수값을 갖는 인덱스 리스트(indices)를 만들고 확인한다.\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "print(indices)\n",
    "\n",
    "# 인덱스 리스트를 랜덤하게 섞고 확인한다.\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 분할 비율(valid_size)에 따른 지점의 인덱스 값(split)을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# 분할 비율(valid_size)에 해당하는 인덱스를 계산하고 확인해 본다.\n",
    "split = int(np.floor(num_train * valid_size))\n",
    "print(split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. split을 기준으로 학습 데이터 인덱스 리스트와 테스트 인덱스 리스트로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 113, 123, 147, 146, 65, 43, 17, 60, 20, 121, 24, 35, 62, 118, 28, 70, 140, 16, 84, 114, 45, 12, 119, 82, 37, 30, 6, 10, 96, 144, 50, 79, 71, 129, 58, 141, 25, 31, 98, 132, 59, 104, 130, 44, 32, 23, 11, 136, 56, 124, 83, 26, 106, 143, 9, 18, 109, 85, 41, 48, 38, 135, 64, 57, 81, 142, 68, 95, 112, 0, 47, 2, 40, 139, 115, 13, 153, 110, 116, 89, 145, 52, 90, 128, 42, 8, 15, 77, 46, 34, 99, 87, 154, 122, 4, 54, 53, 7, 21, 137, 117, 36, 69, 134, 111, 148, 80, 97, 151, 125, 74, 120, 107, 152, 39, 61, 133, 78, 73, 126, 63, 150, 5]\n",
      "[131, 86, 3, 33, 105, 138, 14, 55, 66, 75, 127, 51, 72, 103, 88, 92, 22, 29, 19, 94, 91, 102, 108, 27, 93, 1, 76, 149, 101, 49, 100]\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 인덱스 리스트 및 테스트 인덱스 리스트를 만들고 확인해 본다.\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "print(train_idx)\n",
    "print(test_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 데이터 세트들의 샘플러 및 로더를 만들고 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basalt', 'Highland']\n",
      "['Basalt', 'Highland']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 샘플링 방식(SubsetRandomSampler)을 지정한다\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# 데이터 로딩을 위한 loader를 만든다. (sampler, 배치 사이즈 등 지정)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "\n",
    "# 학습 loader와 테스트 loader의 class들을 출력하여 확인한다.\n",
    "print(trainloader.dataset.classes)\n",
    "print(testloader.dataset.classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드들을 묶어서 load_split_train_test() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드들을 묶어서 load_split_train_test() 함수를 만든다. (입력 : 데이터 디렉토리, 분할 비율) (출력 : 학습 데이터 로더, 테스트 데이터 로더)\n",
    "def load_split_train_test(data_dir, valid_size):\n",
    "    t_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "    test_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(num_train * valid_size))\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "    train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_split_train_test() 함수를 이용하여 trainloader, testloader를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_split_train_test() 함수를 이용하여 trainloader와 testloader를 만들고 확인한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 데이터 샘플들을 살펴본다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의의 데이터를 로딩한 후 이미지와 레이블을 반환하는 get_random_images() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의 선택한 이미지를 표시해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 이미지와 레이블을 랜덤하게 가져온다.\n",
    "\n",
    "# 픽셀 배열을 PIL 형식의 이미지로 변환하고 이미지 크기를 지정한다.\n",
    "\n",
    "\n",
    "# 학습 데이터의 class 리스트를 얻는다.\n",
    "\n",
    "\n",
    "# 이미지를 표시하기 위한 설정을 한다.\n",
    "\n",
    "\n",
    "# 주피터 노트북에 이미지를 표시한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 모델을 가져와 FCL(Fully Connected Layer)을 수정한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute device를 정한다(CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute device를 정하고 확인한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전학습된 ResNet50 모델을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 모델을 pretrained=True로 설정한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 수정 전의 ResNet50 모델을 확인해 본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCL을 수정한다.(뉴런 구축, 신경망 연결, FCL의 layer 설정 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 신경망 구축 : 전이학습을 위해 모델의 가중치를 freeze 한다.\n",
    "    \n",
    "# 뉴런들을 연결하여 신경망을 생성한다.\n",
    "\n",
    "\n",
    "# q: explain the above code\n",
    "# a: 2048개의 입력을 받아 512개의 출력을 내고, ReLU 함수를 거쳐 0.2의 확률로 Dropout을 적용한다.\n",
    "# 512개의 입력을 받아 2개의 출력을 내고, LogSoftmax 함수를 거쳐 1차원으로 변환한다.\n",
    "# 1차원으로 변환된 출력을 갖는 신경망을 생성한다.\n",
    "\n",
    "# 손실함수를 Cross entropy loss 함수로 지정한다.\n",
    "\n",
    "# why\n",
    "# optimizer를 Adam으로 지정한다.\n",
    "# what is Adam\n",
    "#\n",
    "\n",
    "# 신경망을 compute device로 보낸다.\n",
    "\n",
    "# 종료 여부를 출력한다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) FCL을 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델의 FCL을 학습시키고 테스트 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습/검증을 위한 변수를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에폭 및 출력 간격을 설정한다.\n",
    "\n",
    "# 손실 변수들을 초기화 한다.\n",
    "\n",
    "# 현재의 학습 단계를 표현하는 steps 변수를 0으로 초기화 한다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정한 에폭만큼 모델을 학습시키며 검증/평가 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정한 회수만큼 학습 후 테스트 및 평가해 본다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 학습 손실값과 테스트 손실값을 그래프로 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# in this graph, what is x-axis? y-axis?\n",
    "# x-axis: epoch\n",
    "# y-axis: loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습/테스트 완료된 모델을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추후 로드하여 사용할 수 있도록 학습/테스트 완료된 모델을 저장한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 완성된 모델을 사용하여 예측한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장한 모델을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 모델을 불러온다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 불러온 모델을 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 예측을 위해 predict_image() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5개의 이미지를 임의로 가져와 예측해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
